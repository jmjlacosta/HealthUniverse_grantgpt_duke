{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cec12e-6009-4351-9538-be60de15b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# Define Inputs\n",
    "corpus = \"Duke - Copd Trials\"\n",
    "patient_id = \"kp\"\n",
    "queries = \"\"\"CC: increased SOB. HPI: Pt is a 53 yo man with a 50 pack-year history of smoking, \n",
    "and severe COPD who returns to the clinic for follow up after a 4 day hospitalization for a COPD exacerbation. \n",
    "Currently he takes Spiriva 1 puff qd, salmeterol 1 puff q12, fluticasone 2 puffs q 4-6 hours,, \n",
    "but he remains symptomatic and not fully controlled on his current medications. \n",
    "LFTs: Normal Albumiin: 4mg/dl Total bilirubin: 1mg/dl INR: Normal\"\"\"\n",
    "\n",
    "k = 20  # Number of results\n",
    "\n",
    "# Define paths\n",
    "corpus_base_path = \"duke_corpus\"\n",
    "dataset_path = \"dataset/data\"\n",
    "corpus_mapping = {\n",
    "    \"Duke - All Trials\": \"all\",\n",
    "    \"Duke - Oncology Trials\": \"onco\",\n",
    "    \"Duke - Copd Trials\": \"copd\"\n",
    "}\n",
    "\n",
    "selected_corpus_folder = corpus_mapping[corpus]\n",
    "corpus_file_path = os.path.join(corpus_base_path, selected_corpus_folder, \"corpus.jsonl\")\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(dataset_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb81887c-4f76-48e5-9154-eecadf39759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied duke_corpus/copd/corpus.jsonl → dataset/data/corpus.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Check if corpus file exists\n",
    "if not os.path.exists(corpus_file_path):\n",
    "    raise FileNotFoundError(f\"Corpus file not found at {corpus_file_path}\")\n",
    "\n",
    "# Copy corpus.jsonl to dataset/data folder\n",
    "shutil.copy(corpus_file_path, os.path.join(dataset_path, \"corpus.jsonl\"))\n",
    "\n",
    "print(f\"Copied {corpus_file_path} → {dataset_path}/corpus.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb66dc1a-5e28-4de2-b8c8-dd121f00cd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved queries to dataset/data/queries.jsonl\n"
     ]
    }
   ],
   "source": [
    "def generate_jsonl_file(patient_id, queries):\n",
    "    \"\"\"Save query in JSONL format.\"\"\"\n",
    "    query_data = {\"_id\": patient_id, \"text\": queries}\n",
    "    jsonl_file = os.path.join(dataset_path, \"queries.jsonl\")\n",
    "\n",
    "    with open(jsonl_file, \"w\") as f:\n",
    "        json.dump(query_data, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    return jsonl_file\n",
    "\n",
    "# Generate and save queries\n",
    "queries_file = generate_jsonl_file(patient_id, queries)\n",
    "print(f\"Saved queries to {queries_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a82ac55-4055-40f7-aa94-aa3e3a3fc2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword generation successful: \n"
     ]
    }
   ],
   "source": [
    "# Run keyword generation\n",
    "command = [\"python3\", \"trialgpt_retrieval/keyword_generation.py\"]\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"Error in keyword generation:\", result.stderr)\n",
    "else:\n",
    "    print(\"Keyword generation successful:\", result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f552b023-d11d-43c3-b1e4-847a263a464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in hybrid fusion retrieval: Traceback (most recent call last):\n",
      "  File \"/home/jmjl/HealthUniverse/apps/HealthUniverse_triapgpt_duke_lite/trialgpt_retrieval/hybrid_fusion_retrieval.py\", line 182, in <module>\n",
      "    print(process_queries(corpus, q_type, k, bm25_wt, medcpt_wt))\n",
      "  File \"/home/jmjl/HealthUniverse/apps/HealthUniverse_triapgpt_duke_lite/trialgpt_retrieval/hybrid_fusion_retrieval.py\", line 144, in process_queries\n",
      "    medcpt, medcpt_nctids = get_medcpt_corpus_index(corpus)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# command = [\n",
    "#     \"python3\", \"trialgpt_retrieval/hybrid_fusion_retrieval.py\", \n",
    "#     \"data\", \"gpt-4o\", str(k), \"1\", \"1\"\n",
    "# ]\n",
    "\n",
    "# result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "# if result.returncode != 0:\n",
    "#     print(\"Error in hybrid fusion retrieval:\", result.stderr)\n",
    "# else:\n",
    "#     print(\"Hybrid fusion retrieval successful:\", result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5a550a-ef20-4dbc-b4f4-062e41ad8756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized query processing complete.\n",
      "Hybrid fusion retrieval successful: \n"
     ]
    }
   ],
   "source": [
    "command = [\n",
    "    \"python3\", \"trialgpt_retrieval/hybrid_fusion_retrieval.py\", \n",
    "    \"data\", \"gpt-4o\", str(k), \"1\", \"1\"\n",
    "]\n",
    "\n",
    "# Open process\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1, universal_newlines=True)\n",
    "\n",
    "# Print output in real-time\n",
    "for line in process.stdout:\n",
    "    print(line, end=\"\")  # Print each line as it appears\n",
    "\n",
    "# Wait for process to complete and capture errors if any\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "if process.returncode != 0:\n",
    "    print(\"Error in hybrid fusion retrieval:\", stderr)\n",
    "else:\n",
    "    print(\"Hybrid fusion retrieval successful:\", stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e04548b-9aa4-4404-bcc9-a4b7b6816dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial retrieval successful: kp\n",
      "Results saved to dataset/data/retrieved_trials.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "command = [\"python3\", \"trialgpt_retrieval/retrieval.py\", \"dataset/data/qid2nctids_results.json\"]\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"Error in trial retrieval:\", result.stderr)\n",
    "else:\n",
    "    print(\"Trial retrieval successful:\", result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "839fb625-e193-493c-80f6-d5efb5bc7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching successful: \n"
     ]
    }
   ],
   "source": [
    "command = [\"python3\", \"trialgpt_matching/run_matching.py\", \"data\", \"gpt-4o\"]\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"Error in matching:\", result.stderr)\n",
    "else:\n",
    "    print(\"Matching successful:\", result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52a7786f-d3cf-47a6-ad39-e983a31db467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial info generation successful: \n"
     ]
    }
   ],
   "source": [
    "command = [\"python3\", \"trialgpt_matching/generate_trial_info.py\", \"data\"]\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"Error in generating trial info:\", result.stderr)\n",
    "else:\n",
    "    print(\"Trial info generation successful:\", result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "680af4d5-bd08-4fe6-ae76-09793d922ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation successful: \n"
     ]
    }
   ],
   "source": [
    "command = [\n",
    "    \"python3\", \"trialgpt_ranking/run_aggregation.py\", \n",
    "    \"data\", \"gpt-4o\", \"dataset/data/matching_results.json\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"Error in aggregation:\", result.stderr)\n",
    "else:\n",
    "    print(\"Aggregation successful:\", result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c35b4ca2-c0e2-45d2-9315-1a54ae13ca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in ranking: Traceback (most recent call last):\n",
      "  File \"/home/jmjl/HealthUniverse/apps/trialgpt_duke/trialgpt_ranking/rank_results.py\", line 63, in <module>\n",
      "    agg_results = json.load(open(agg_results_path))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'dataset/data/aggregation_results.json'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "command = [\n",
    "    \"python3\", \"trialgpt_ranking/rank_results.py\", \n",
    "    \"dataset/data/matching_results.json\", \n",
    "    \"dataset/data/aggregation_results.json\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"Error in ranking:\", result.stderr)\n",
    "else:\n",
    "    print(\"Ranking successful:\", result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af001e-f3af-4155-a0af-387a168cf050",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_path = \"dataset/data/1_FINAL_ranking_results.txt\"\n",
    "\n",
    "if os.path.exists(ranking_path):\n",
    "    with open(ranking_path, \"r\") as f:\n",
    "        rankings = f.read()\n",
    "    print(\"Ranking Results:\\n\", rankings)\n",
    "else:\n",
    "    print(\"Ranking results file not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afcfe41-7de4-4f56-87e9-f4d90d430efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = \"dataset/data/results.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, dataset_path)\n",
    "            zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"Results ZIP file created at {zip_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
